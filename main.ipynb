{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cde527f2",
   "metadata": {},
   "source": [
    "# Modelos probados:\n",
    "- Gemini 2.5 flash\n",
    "- qwen3:8b\n",
    "- granite3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85713f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "HUGGINGFACE_API_KEY = \"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\"\n",
    "GEMINI_API_KEY = \"AIzaSyAJRz8G-3RO9ffbEIsaej-bskTHGmFpQAc\"\n",
    "\n",
    "OLLAMA_SERVER = \"https://ollama.nest0r.dev/\"\n",
    "OLLAMA_USERNAME = \"nestor\"\n",
    "OLLAMA_PASSWORD = \"nestor12\"\n",
    "\n",
    "HOW_MANY_MESSAGES_TO_CHECK_SPAM = 5\n",
    "\n",
    "MODELS = {\n",
    "    \"gemini\" : \"gemini-2.5-flash-preview-04-17\",\n",
    "    \"qwen3\": \"qwen3:8b\",\n",
    "    \"granite3.3\": \"granite3.3:8b\",\n",
    "}\n",
    "\n",
    "# Inicializar el cliente de OpenAI\n",
    "client = OpenAI(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "# Variables de configuración\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98122506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response):\n",
    "    \"\"\"\n",
    "    Funcion para formatear la respuesta.\n",
    "    Obtiene solo el contenido de la respuesta y se limpia mediante regex \n",
    "    \"\"\"\n",
    "\n",
    "    response_content = response.choices[0].message.content\n",
    "    formatted_response = re.sub(r'^\\s*|\\s*$', '', response_content)\n",
    "    \n",
    "    return formatted_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff21c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leer el archivo csv\n",
    "df = pd.read_csv('./INPUT/spam.csv', encoding='latin-1')\n",
    "\n",
    "# Borrar Unnamed: 2\tUnnamed: 3\tUnnamed: 4\n",
    "df = df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a646b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir entre train y test\n",
    "train = df.sample(frac=0.8, random_state=42)\n",
    "test = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0847c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             message label_zero_shot  \\\n",
      "0  U dun say so early hor... U c already then say...            spam   \n",
      "1  Nah I don't think he goes to usf, he lives aro...             ham   \n",
      "2  FreeMsg Hey there darling it's been 3 week's n...            spam   \n",
      "3  Had your mobile 11 months or more? U R entitle...            spam   \n",
      "4                         Oh k...i'm watching here:)             ham   \n",
      "\n",
      "  real_label  \n",
      "0        ham  \n",
      "1        ham  \n",
      "2       spam  \n",
      "3       spam  \n",
      "4        ham  \n"
     ]
    }
   ],
   "source": [
    "# Zero-shot\n",
    "\n",
    "# Crear un dataframe para almacenar las respuestas\n",
    "response_df_zero_shot = pd.DataFrame(columns=['message', 'label_zero_shot', 'real_label'])\n",
    "\n",
    "# Iterar sobre los mensajes de prueba\n",
    "for i in range(HOW_MANY_MESSAGES_TO_CHECK_SPAM):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \n",
    "             \"\"\"\n",
    "                Eres un experto en clasificación de mensajes, se te enviará un mensaje y debes clasificarlo como spam o no spam.\n",
    "                Responde solo con la palabra \"spam\", en caso de ser spam, o \"ham\", en caso de no ser spam.\n",
    "             \"\"\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": test.iloc[i]['message']\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Guardar la respuesta en el dataframe\n",
    "    new_row = pd.DataFrame([{\n",
    "        'message': test.iloc[i]['message'],\n",
    "        'label_zero_shot': format_response(response),\n",
    "        'real_label': test.iloc[i]['type']\n",
    "    }])\n",
    "    response_df_zero_shot = pd.concat([response_df_zero_shot, new_row], ignore_index=True)\n",
    "    \n",
    "    # Sleep para evitar el límite de peticiones\n",
    "    time.sleep(1)\n",
    "\n",
    "# Mostrar el resultado\n",
    "# print(response_df_zero_shot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "736406b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Zero-Shot: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Mostrar estadisticas de accuracy\n",
    "accuracy_zero_shot = (response_df_zero_shot['label_zero_shot'] == response_df_zero_shot['real_label']).mean()\n",
    "print(f\"Accuracy Zero-Shot: {accuracy_zero_shot:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1828d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del Few-Shot:\n",
      "                                             message label_few_shot real_label\n",
      "0  U dun say so early hor... U c already then say...            ham        ham\n",
      "1  Nah I don't think he goes to usf, he lives aro...            ham        ham\n",
      "2  FreeMsg Hey there darling it's been 3 week's n...           spam       spam\n",
      "3  Had your mobile 11 months or more? U R entitle...           spam       spam\n",
      "4                         Oh k...i'm watching here:)            ham        ham\n",
      "\n",
      "Accuracy Few-Shot: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Few-shot\n",
    "\n",
    "# Crear un dataframe para almacenar las respuestas\n",
    "response_df_few_shot = pd.DataFrame(columns=['message', 'label_few_shot', 'real_label'])\n",
    "\n",
    "# Seleccionar algunos ejemplos del conjunto de entrenamiento para few-shot\n",
    "few_shot_examples = train.sample(3, random_state=42) # Tomamos 3 ejemplos\n",
    "\n",
    "# Iterar sobre los mensajes de prueba\n",
    "for i in range(HOW_MANY_MESSAGES_TO_CHECK_SPAM):\n",
    "    # Construir los mensajes para el few-shot\n",
    "    messages_few_shot = [\n",
    "        {\"role\": \"system\", \"content\":\n",
    "         \"\"\"\n",
    "            Eres un experto en clasificación de mensajes, se te enviará un mensaje y debes clasificarlo como spam o no spam.\n",
    "            Responde solo con la palabra \"spam\", en caso de ser spam, o \"ham\", en caso de no ser spam.\n",
    "            Aquí tienes algunos ejemplos:\n",
    "         \"\"\"}\n",
    "    ]\n",
    "    # Añadir los ejemplos de few-shot\n",
    "    for index, row in few_shot_examples.iterrows():\n",
    "        messages_few_shot.append({\"role\": \"user\", \"content\": row['message']})\n",
    "        messages_few_shot.append({\"role\": \"assistant\", \"content\": row['type']})\n",
    "\n",
    "    # Añadir el mensaje actual a clasificar\n",
    "    messages_few_shot.append({\"role\": \"user\", \"content\": test.iloc[i]['message']})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        messages=messages_few_shot\n",
    "    )\n",
    "\n",
    "    # Guardar la respuesta en el dataframe\n",
    "    new_row = pd.DataFrame([{\n",
    "        'message': test.iloc[i]['message'],\n",
    "        'label_few_shot': format_response(response),\n",
    "        'real_label': test.iloc[i]['type']\n",
    "    }])\n",
    "    response_df_few_shot = pd.concat([response_df_few_shot, new_row], ignore_index=True)\n",
    "\n",
    "    # Sleep para evitar el límite de peticiones\n",
    "    time.sleep(1)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Resultados del Few-Shot:\")\n",
    "print(response_df_few_shot)\n",
    "\n",
    "# Mostrar estadisticas de accuracy\n",
    "accuracy_few_shot = (response_df_few_shot['label_few_shot'] == response_df_few_shot['real_label']).mean()\n",
    "print(f\"\\nAccuracy Few-Shot: {accuracy_few_shot:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66865ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del Few-Shot:\n",
      "                                             message label_chain_of_thoughts  \\\n",
      "0  U dun say so early hor... U c already then say...                     ham   \n",
      "1  Nah I don't think he goes to usf, he lives aro...                     ham   \n",
      "2  FreeMsg Hey there darling it's been 3 week's n...                    spam   \n",
      "3  Had your mobile 11 months or more? U R entitle...                    spam   \n",
      "4                         Oh k...i'm watching here:)                     ham   \n",
      "\n",
      "  real_label  \n",
      "0        ham  \n",
      "1        ham  \n",
      "2       spam  \n",
      "3       spam  \n",
      "4        ham  \n",
      "\n",
      "Accuracy Few-Shot: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Chain of thoughts\n",
    "\n",
    "# Crear un dataframe para almacenar las respuestas\n",
    "response_df_chain_of_thoughts = pd.DataFrame(columns=['message', 'label_chain_of_thoughts', 'real_label'])\n",
    "\n",
    "# Iterar sobre los mensajes de prueba\n",
    "for i in range(HOW_MANY_MESSAGES_TO_CHECK_SPAM):\n",
    "    response = client.chat.completions.create(\n",
    "        # Usamos un modelo con capacidad de razonamiento\n",
    "        model=\"gemini-2.5-pro-exp-03-25\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \n",
    "             \"\"\"\n",
    "                Eres un experto en clasificación de mensajes, se te enviará un mensaje y debes clasificarlo como spam o no spam.\n",
    "                Responde solo con la palabra \"spam\", en caso de ser spam, o \"ham\", en caso de no ser spam.\n",
    "             \"\"\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": test.iloc[i]['message']\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Guardar la respuesta en el dataframe\n",
    "    new_row = pd.DataFrame([{\n",
    "        'message': test.iloc[i]['message'],\n",
    "        'label_chain_of_thoughts': format_response(response),\n",
    "        'real_label': test.iloc[i]['type']\n",
    "    }])\n",
    "    response_df_chain_of_thoughts = pd.concat([response_df_chain_of_thoughts, new_row], ignore_index=True)\n",
    "    \n",
    "    # Sleep para evitar el límite de peticiones\n",
    "    time.sleep(1)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Resultados del Chain of thoughts:\")\n",
    "print(response_df_chain_of_thoughts)\n",
    "\n",
    "# Mostrar estadisticas de accuracy\n",
    "accuracy_chain_of_thoughts = (response_df_chain_of_thoughts['label_chain_of_thoughts'] == response_df_chain_of_thoughts['real_label']).mean()\n",
    "print(f\"\\nAccuracy Chain of thoughts: {accuracy_chain_of_thoughts:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
